{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae0ea33c",
   "metadata": {},
   "source": [
    "## What are Tensors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5eaa25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4f545d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#created data directly from data \n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fae18fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy np_array value: \n",
      " [[1 2]\n",
      " [3 4]] \n",
      "\n",
      "Tensor x_np value: \n",
      " tensor([[1, 2],\n",
      "        [3, 4]]) \n",
      "\n",
      "Numpy np_array after * 2 operations: \n",
      " [[2 4]\n",
      " [6 8]] \n",
      "\n",
      "Tensor x_np value after modifying numpy array: \n",
      " tensor([[2, 4],\n",
      "        [6, 8]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tensors and NP share same memory address when you tell them to\n",
    "\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "\n",
    "print(f\"Numpy np_array value: \\n {np_array} \\n\")\n",
    "print(f\"Tensor x_np value: \\n {x_np} \\n\")\n",
    "\n",
    "np.multiply(np_array, 2, out= np_array)\n",
    "\n",
    "print(f\"Numpy np_array after * 2 operations: \\n {np_array} \\n\")\n",
    "print(f\"Tensor x_np value after modifying numpy array: \\n {x_np} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58933977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.6158, 0.7247],\n",
      "        [0.3640, 0.9249]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#first line makes an array of ones \n",
    "x_ones = torch.ones_like(x_data) #retains properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "#randomizes in the same arr space \n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) #overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "478a738c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.5549, 0.7276, 0.8647],\n",
      "        [0.2712, 0.3799, 0.6636]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#makes different types of tensors with the same shape\n",
    "\n",
    "shape = (2, 3)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor  = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "#print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39975b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tenor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "#displays information about the tensor\n",
    "\n",
    "tensor = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tenor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb70504f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device tensor is stored on: cpu...nice try though\n"
     ]
    }
   ],
   "source": [
    "#Trying to move to CUDA \n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')\n",
    "if tensor.device == 'cuda':\n",
    "    print(\"Congrats! You have cuda!\")\n",
    "else:\n",
    "    print(f\"Device tensor is stored on: {tensor.device}...nice try though\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d860acad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column:  tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#numpy-like indexing and slicing\n",
    "\n",
    "tensor = torch.ones(4, 4)\n",
    "print('First row:', tensor[0])\n",
    "print('First column: ', tensor[:, 0])\n",
    "print('Last column:', tensor[..., -1])\n",
    "tensor[:, 1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b0cca42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n",
      "\n",
      "\n",
      "tensor([[[1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "          1.0000, 0.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "          1.0000, 0.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "          1.0000, 0.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "          1.0000, 0.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[0.2698, 0.9234, 0.4556, 0.3567, 0.0654, 0.9186, 0.3638, 0.2946,\n",
      "          0.6148, 0.1557, 0.6704, 0.4572],\n",
      "         [0.7945, 0.3339, 0.6301, 0.4802, 0.2068, 0.5387, 0.5218, 0.7434,\n",
      "          0.7248, 0.7502, 0.4696, 0.9733],\n",
      "         [0.0707, 0.7180, 0.1242, 0.7542, 0.3979, 0.1657, 0.0017, 0.4645,\n",
      "          0.9799, 0.3748, 0.5102, 0.7159],\n",
      "         [0.3429, 0.5911, 0.8175, 0.7901, 0.9260, 0.8690, 0.7173, 0.4129,\n",
      "          0.3152, 0.4373, 0.9909, 0.8285]]])\n"
     ]
    }
   ],
   "source": [
    "#torch.cat concatenates, torch.stack joins in new dimension\n",
    "\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim= 1)\n",
    "print(t1)\n",
    "print(f'\\n')\n",
    "t2 = torch.stack((t1, torch.rand(4, 12)))\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60349b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication \n",
    "\n",
    "#transposes the tensor\n",
    "#[[1, 2, 3] [4, 5, 6], [7, 8, 9]] becomes [[1, 4, 7]. [2, 5, 6], [3, 6, 9]]\n",
    "\n",
    "y1 = tensor @ tensor.T\n",
    "\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "#Computes the element-wise product\n",
    "\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)\n",
    "\n",
    "\n",
    "#I'm honestly not sure what the tutorial was trying\n",
    "#to accomplish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a7528c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "#aggregates values into one tensor\n",
    "\n",
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f247e142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "#Don't do this\n",
    "\n",
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5) #adds in place (BAD) but fast\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c5bcd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#Tensors on the CPU and NP arrays can share memory locations\n",
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69528356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de9b8cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NP array to tensor\n",
    "\n",
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0aa7a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6744adf8",
   "metadata": {},
   "source": [
    "## Loading and normalizing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "caba2bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#sets everything up\n",
    "#training data is already known\n",
    "#test data has not been trained\n",
    "\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root = \"data\",\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7866ea0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "#lists the things from the training data\n",
    "figure = plt.figure(figsize =(8, 8))\n",
    "cols, rows = 3, 3\n",
    "\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5db67ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#shuffle\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9e07ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Sandal\n"
     ]
    }
   ],
   "source": [
    "#Display image and label \n",
    "\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "label_name = list(labels_map.values())[label]\n",
    "print(f\"Label: {label_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6601a6",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dca0f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "221c7793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "409fa506",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            #first input layer is 28x28\n",
    "            nn.Linear(28*28, 512),\n",
    "            #ReLU activation\n",
    "            #AKA rectified linear activation function \n",
    "            #AKAAKA makes things either 0 or positive\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ad695402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8e9719fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([55])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device = device )\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c964ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Linear weights: Parameter containing:\n",
      "tensor([[ 1.0338e-02, -1.1956e-02, -2.9492e-05,  ..., -2.5474e-02,\n",
      "         -1.0354e-02,  2.2475e-02],\n",
      "        [-2.6487e-02, -2.7928e-02,  1.2682e-02,  ..., -2.4515e-02,\n",
      "          3.5680e-02,  8.6003e-03],\n",
      "        [-4.2739e-04,  1.4339e-02,  2.2475e-02,  ..., -2.4439e-02,\n",
      "          2.4710e-02, -1.8112e-02],\n",
      "        ...,\n",
      "        [-2.5734e-02,  3.2784e-02,  4.4933e-03,  ...,  1.5198e-02,\n",
      "         -7.5404e-03,  2.2286e-02],\n",
      "        [-3.1251e-02, -3.2747e-02, -3.2712e-02,  ...,  2.5230e-02,\n",
      "         -1.2233e-02,  3.1318e-02],\n",
      "        [-1.7011e-02,  3.1351e-02,  2.4173e-02,  ...,  2.3219e-02,\n",
      "         -3.2210e-03, -1.1448e-02]], requires_grad=True) \n",
      "\n",
      "First Linear biases: Parameter containing:\n",
      "tensor([ 1.5640e-02, -3.2947e-02,  2.0174e-02, -2.9439e-02, -3.5209e-02,\n",
      "         2.2723e-02, -2.6893e-02, -2.9579e-02, -1.1997e-02, -2.3149e-02,\n",
      "         5.5825e-03,  3.4269e-02,  1.5609e-02,  3.3275e-03, -1.0903e-02,\n",
      "         2.5471e-02,  3.3622e-02, -3.4586e-02, -2.3871e-03,  1.5237e-02,\n",
      "         3.4628e-02, -2.7798e-02, -3.2816e-02,  3.2347e-02,  1.4504e-02,\n",
      "        -2.9114e-02,  2.5374e-02, -2.5514e-02, -3.1666e-02,  2.7272e-02,\n",
      "         2.9461e-02,  6.8953e-04,  6.3344e-03,  3.1117e-02,  2.5050e-03,\n",
      "        -3.1668e-02, -5.3184e-03, -1.9588e-02, -8.1648e-03, -2.1084e-02,\n",
      "        -2.6742e-02, -3.0500e-03,  1.9874e-02, -1.0201e-02, -1.5918e-02,\n",
      "         3.4504e-02, -1.0766e-02, -1.7255e-02,  2.0111e-02, -2.4304e-02,\n",
      "         3.3008e-02, -3.1767e-02,  1.4688e-02, -1.3100e-02, -5.2621e-03,\n",
      "         1.6055e-02, -1.7889e-02, -2.7968e-02, -9.7281e-03, -8.6024e-03,\n",
      "         3.2792e-02, -8.3950e-03, -2.3608e-02, -6.9769e-03,  6.1716e-03,\n",
      "        -6.1587e-03,  2.9066e-02,  1.5195e-02,  2.9335e-02,  1.9358e-02,\n",
      "         2.0752e-02, -1.3566e-02,  2.4945e-02, -1.7376e-02,  2.0089e-02,\n",
      "         3.5059e-02,  1.8113e-02, -2.8429e-02,  1.8605e-02,  2.3231e-02,\n",
      "         5.1602e-03, -2.9474e-05,  3.4637e-02, -1.7322e-02,  2.1424e-02,\n",
      "         1.4134e-02, -1.1811e-02, -1.6112e-02,  3.0725e-02, -5.2847e-03,\n",
      "         2.8448e-02,  3.2295e-02,  4.7903e-03, -2.2963e-03, -8.6425e-03,\n",
      "         2.3434e-02,  2.4472e-03,  7.3113e-03,  1.5167e-02,  1.1045e-02,\n",
      "        -2.0516e-02, -2.7229e-02,  1.5706e-02,  3.1996e-02,  1.4240e-02,\n",
      "        -3.3798e-02,  2.9222e-02,  2.9220e-02,  2.1020e-02,  2.8545e-02,\n",
      "        -3.1559e-02,  3.1581e-02,  2.1600e-02,  3.2836e-02,  2.8910e-02,\n",
      "         2.1843e-02, -8.8317e-03,  3.1062e-02, -1.5829e-02,  2.2890e-02,\n",
      "         3.3113e-02, -1.6937e-02, -1.3881e-02, -1.0677e-02,  2.9737e-02,\n",
      "         3.5082e-02, -3.3698e-03, -2.2353e-02, -1.9146e-02,  9.5042e-03,\n",
      "         3.2522e-02, -3.5163e-02, -3.4498e-02,  2.7195e-02, -4.3909e-03,\n",
      "        -1.6574e-02, -2.4931e-03,  1.3107e-02, -2.9200e-02,  2.9463e-02,\n",
      "        -2.2727e-02, -1.4169e-02, -2.4209e-03,  3.5631e-02,  1.5012e-02,\n",
      "        -3.5176e-02,  4.9098e-03, -2.4726e-02,  3.4120e-02,  1.9647e-02,\n",
      "        -2.3249e-02,  2.4317e-02,  1.4145e-02,  2.5491e-02,  2.7615e-02,\n",
      "        -1.9137e-02,  1.0564e-02,  9.7698e-03, -2.1948e-02,  4.8231e-03,\n",
      "         1.7737e-02, -3.0629e-02,  1.0245e-02, -3.3350e-02,  2.3221e-02,\n",
      "         2.1334e-02,  4.2581e-03,  2.2214e-02,  8.3565e-03,  3.2050e-02,\n",
      "         7.4921e-03, -5.7640e-03,  1.2565e-02, -1.2712e-02, -8.7190e-03,\n",
      "         2.6575e-02,  2.5011e-02,  1.0621e-02, -2.4427e-02, -5.2382e-03,\n",
      "         3.4507e-02,  2.8488e-03,  1.0422e-03,  3.0710e-02,  3.2312e-02,\n",
      "        -2.0662e-02, -4.5321e-05, -1.5187e-02, -1.5334e-02,  2.5194e-02,\n",
      "         8.6422e-03,  2.2016e-02, -1.6407e-02, -9.4143e-03,  1.9371e-02,\n",
      "        -1.1462e-02,  2.8650e-02, -1.5661e-02,  1.1694e-02,  3.4313e-03,\n",
      "        -2.8239e-02,  1.8788e-02,  1.7684e-03, -1.2021e-02,  5.1114e-03,\n",
      "         2.3476e-02,  1.8849e-02, -2.9496e-02, -2.4225e-02, -3.0009e-02,\n",
      "         1.8447e-02, -6.1334e-03,  1.0804e-03,  2.3796e-02, -1.3598e-02,\n",
      "        -9.8157e-03, -2.9936e-02, -2.0716e-02,  3.1611e-02,  1.3544e-02,\n",
      "         3.4168e-02, -1.5697e-02, -3.0025e-02, -3.5592e-02,  4.9575e-03,\n",
      "         1.3682e-02, -1.1649e-02, -2.4665e-02, -2.8864e-02, -3.0253e-02,\n",
      "        -1.7232e-02,  2.8608e-02,  6.0054e-03, -1.8586e-02,  3.4909e-02,\n",
      "        -2.8080e-03, -1.7470e-02, -3.2127e-03,  8.6080e-03,  2.6690e-02,\n",
      "         1.2991e-02,  2.9022e-02,  2.2328e-03,  1.7525e-02,  3.1950e-02,\n",
      "        -2.4127e-02, -2.9608e-02, -2.6696e-02, -1.0809e-02,  3.0849e-02,\n",
      "        -2.9422e-02, -3.4771e-02,  9.7901e-03,  3.0717e-02,  3.2562e-03,\n",
      "         9.9843e-03,  1.6150e-02, -5.3584e-04, -2.7272e-02,  3.0433e-02,\n",
      "         1.8441e-02,  2.0008e-02, -6.9241e-03, -3.5530e-02,  2.8933e-02,\n",
      "        -1.3782e-02,  2.4697e-02,  2.4205e-02, -6.1634e-03, -3.2502e-02,\n",
      "        -1.2036e-02, -4.6249e-03,  1.6043e-02, -1.9132e-02, -3.0665e-02,\n",
      "        -2.5149e-02, -2.6151e-02, -1.4373e-02, -2.4552e-02, -3.2590e-02,\n",
      "        -2.2849e-03, -3.0161e-02,  2.5927e-02, -1.4016e-03,  3.0512e-02,\n",
      "         2.5877e-02, -1.1498e-02,  2.9247e-02,  6.7517e-03, -5.7092e-03,\n",
      "        -3.5330e-04,  8.5967e-03,  2.0507e-02,  3.2543e-03, -1.0405e-02,\n",
      "        -1.3038e-02, -1.2278e-02, -2.7993e-02, -7.8838e-03, -1.4750e-02,\n",
      "        -2.1656e-02, -4.3350e-03,  1.5289e-02, -3.0366e-02, -2.4667e-02,\n",
      "        -4.8436e-04, -3.1070e-02,  6.0859e-03,  3.2797e-02,  2.0664e-02,\n",
      "        -1.2625e-02, -1.4209e-02,  1.4487e-02, -1.4866e-02, -2.1727e-02,\n",
      "        -2.7638e-03,  1.3101e-02, -1.2675e-02, -3.0040e-02, -1.6834e-02,\n",
      "        -2.7340e-02, -1.7930e-03,  3.0515e-02, -7.0612e-03,  2.8113e-03,\n",
      "        -1.6767e-02,  2.9252e-04,  2.9691e-02,  1.8150e-02, -2.1417e-02,\n",
      "        -2.0778e-02,  1.6172e-02,  1.2552e-02, -1.4276e-03,  3.0451e-02,\n",
      "        -2.1234e-02, -9.8952e-05, -3.1755e-02, -3.0029e-02, -3.2727e-02,\n",
      "        -1.2847e-03, -1.4875e-02, -2.7308e-03,  1.7575e-02,  1.4191e-02,\n",
      "         2.1806e-02, -2.5693e-02, -6.2167e-03,  1.0438e-02,  2.9822e-02,\n",
      "        -1.0266e-03,  1.6610e-02,  1.3320e-02, -8.0750e-04,  3.3612e-02,\n",
      "         1.0632e-02, -1.3735e-02,  4.6013e-03,  1.2400e-02,  1.4262e-02,\n",
      "        -5.3287e-04,  1.4074e-02,  8.2328e-03, -3.1508e-02,  3.4668e-02,\n",
      "        -3.2520e-02,  3.2861e-02, -1.1265e-03,  1.6134e-02,  7.5118e-03,\n",
      "         1.0494e-02,  1.4212e-02,  3.3016e-02, -3.5290e-03, -3.4927e-02,\n",
      "         1.6035e-02,  3.5400e-02, -2.4068e-02,  2.4616e-03,  8.0093e-03,\n",
      "         1.4462e-03, -4.0565e-03, -4.3546e-03, -2.6682e-02,  6.0596e-03,\n",
      "        -5.1816e-03, -8.8390e-04,  3.2955e-02, -3.4550e-02,  8.0659e-03,\n",
      "         3.5676e-02,  2.7626e-02,  3.1195e-02, -7.6821e-03,  2.9224e-02,\n",
      "        -9.7237e-03, -4.0434e-03, -3.5040e-02,  3.0164e-02, -2.7669e-02,\n",
      "         2.4365e-02, -5.1027e-03,  2.0165e-02, -2.1838e-02, -5.0016e-04,\n",
      "        -2.9158e-02, -1.6157e-02, -9.9609e-03, -1.8335e-02, -2.2549e-02,\n",
      "        -2.4265e-02,  1.1590e-02,  2.4104e-02, -1.3852e-02, -2.1518e-02,\n",
      "        -5.5519e-03,  1.3611e-02, -1.9665e-02,  5.7964e-03,  1.4236e-02,\n",
      "        -6.8477e-03, -3.1712e-02,  3.1321e-02, -1.2179e-02,  2.8710e-02,\n",
      "        -1.9473e-02,  2.6123e-02, -2.4094e-02, -2.9139e-03, -1.1549e-02,\n",
      "         2.2114e-02, -2.2271e-02, -1.5006e-02,  4.1536e-03,  2.4012e-02,\n",
      "         3.4793e-02, -2.0022e-02,  3.5980e-03, -1.3828e-03,  2.0973e-02,\n",
      "         6.5553e-03,  3.2715e-03, -2.2131e-03,  2.6327e-02,  2.4433e-02,\n",
      "         2.5676e-02,  1.9349e-02, -4.7123e-03, -3.2447e-02,  7.8403e-03,\n",
      "        -1.8652e-02,  1.2431e-02, -2.2399e-02,  1.1675e-02, -3.5105e-03,\n",
      "         3.9574e-03,  5.4858e-03,  1.6780e-02,  1.9882e-03,  1.3573e-03,\n",
      "        -3.8831e-03, -7.1896e-03, -1.5546e-02, -3.2322e-02,  2.3664e-02,\n",
      "        -7.1015e-03, -2.5525e-03, -4.4899e-03, -2.2225e-02, -3.3015e-02,\n",
      "         1.8463e-02, -2.1996e-03,  3.1544e-03, -2.3593e-02, -3.1254e-02,\n",
      "        -6.0455e-03, -6.4832e-04,  3.3775e-02, -3.2889e-02, -2.5956e-02,\n",
      "        -3.2660e-02, -2.3394e-02, -3.1267e-03, -2.0378e-02,  3.1616e-02,\n",
      "         2.6078e-02, -2.0967e-03,  2.6215e-03, -4.9008e-03, -2.6770e-02,\n",
      "        -3.4357e-02,  1.3457e-02,  2.7344e-02, -2.4633e-02,  3.3318e-02,\n",
      "         2.8126e-02,  1.0980e-02, -2.1259e-02, -2.5678e-02,  3.2421e-02,\n",
      "        -3.5534e-02, -2.2102e-02, -6.7839e-03, -1.6466e-02, -3.5506e-02,\n",
      "        -3.4021e-02, -1.1950e-02,  6.4367e-03, -1.6479e-02, -3.4620e-03,\n",
      "         2.6545e-02,  1.9815e-02], requires_grad=True) \n",
      " \n"
     ]
    }
   ],
   "source": [
    "#nn.Linear module randomly inits the weights and bias for each layer\n",
    "#and internally stores the values in Tensors\n",
    "\n",
    "print(f\"First Linear weights: {model.linear_relu_stack[0].weight} \\n\")\n",
    "print(f\"First Linear biases: {model.linear_relu_stack[0].bias} \\n \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2cd0f92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "#takes 3 images of FashionMNIST\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "74160d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "#converts each 2D 28x28 array into a continous array of 784 pixels \n",
    "\n",
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e16e4ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "#Transformation calculation\n",
    "##weight * input + bias\n",
    "\n",
    "#Applies linear transformation on the input using its stored weigths and biases\n",
    "#greyscale is connected to neurons in the hidden layer\n",
    "\n",
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "966e2c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[0.3748, 0.0000, 0.0000, 0.0000, 0.0000, 0.6097, 0.0000, 0.0000, 0.2766,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1121, 0.0126, 0.0000, 0.1395,\n",
      "         0.0000, 0.0789],\n",
      "        [0.3658, 0.0000, 0.0000, 0.0000, 0.0000, 0.5254, 0.0000, 0.0072, 0.4443,\n",
      "         0.0000, 0.2244, 0.1711, 0.0000, 0.0000, 0.0000, 0.3610, 0.0307, 0.0000,\n",
      "         0.0000, 0.0586],\n",
      "        [0.1996, 0.0000, 0.0000, 0.0000, 0.0000, 0.8078, 0.0000, 0.0000, 0.3890,\n",
      "         0.0000, 0.3736, 0.0000, 0.0405, 0.0000, 0.0000, 0.2496, 0.0980, 0.0000,\n",
      "         0.0381, 0.2717]], grad_fn=<ReluBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.3748, 0.0000, 0.0000, 0.0000, 0.0000, 0.6097, 0.0000, 0.0000, 0.2766,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1121, 0.0126, 0.0000, 0.1395,\n",
      "         0.0000, 0.0789],\n",
      "        [0.3658, 0.0000, 0.0000, 0.0000, 0.0000, 0.5254, 0.0000, 0.0072, 0.4443,\n",
      "         0.0000, 0.2244, 0.1711, 0.0000, 0.0000, 0.0000, 0.3610, 0.0307, 0.0000,\n",
      "         0.0000, 0.0586],\n",
      "        [0.1996, 0.0000, 0.0000, 0.0000, 0.0000, 0.8078, 0.0000, 0.0000, 0.3890,\n",
      "         0.0000, 0.3736, 0.0000, 0.0405, 0.0000, 0.0000, 0.2496, 0.0980, 0.0000,\n",
      "         0.0381, 0.2717]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#does ReLU stuff\n",
    "\n",
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2da50d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates an ordered container of modules\n",
    "\n",
    "\n",
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "10d08db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taxes relative max and makes it 1\n",
    "#makes everything relative to that between 0 and 1\n",
    "\n",
    "softmax = nn.Softmax(dim = 1)\n",
    "pred_probab = softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "17f11e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure:  NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 1.0338e-02, -1.1956e-02, -2.9492e-05,  ..., -2.5474e-02,\n",
      "         -1.0354e-02,  2.2475e-02],\n",
      "        [-2.6487e-02, -2.7928e-02,  1.2682e-02,  ..., -2.4515e-02,\n",
      "          3.5680e-02,  8.6003e-03]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([ 0.0156, -0.0329], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0315, -0.0344, -0.0415,  ...,  0.0161,  0.0106,  0.0030],\n",
      "        [ 0.0440, -0.0178, -0.0313,  ...,  0.0197, -0.0194,  0.0368]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([0.0364, 0.0372], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model structure: \", model, \"\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9593763",
   "metadata": {},
   "source": [
    "## Automatic differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bea6530",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "\n",
    "x = torch.ones(5) #input tensor\n",
    "y = torch.zeros(3) # expected output\n",
    "w = torch.randn(5, 3, requires_grad = True)\n",
    "b = torch.randn(3, requires_grad = True)\n",
    "z = torch.matmul(x, w)+b\n",
    "#measures the difference between predicted binary outcomes\n",
    "#and actual binary labels\n",
    "#penalizes predictions that are confident but wrong\n",
    "# =(y*log(p) + (1 - y)* log(1 -p))\n",
    "##where p is the probability of 1 \n",
    "##and y is the actuall class \n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c267270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function for z = <AddBackward0 object at 0x7fa1ccd61d20>\n",
      "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x7fa1ccd624d0>\n"
     ]
    }
   ],
   "source": [
    "print('Gradient function for z =', z.grad_fn)\n",
    "print('Gradient function for loss =', loss.grad_fn)\n",
    "\n",
    "#gradients minimize error between predicted and acutal results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c027b641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1530, 0.0356, 0.3256],\n",
      "        [0.1530, 0.0356, 0.3256],\n",
      "        [0.1530, 0.0356, 0.3256],\n",
      "        [0.1530, 0.0356, 0.3256],\n",
      "        [0.1530, 0.0356, 0.3256]])\n",
      "tensor([0.1530, 0.0356, 0.3256])\n"
     ]
    }
   ],
   "source": [
    "#gradLoss/gradw \n",
    "#gradLoss/gradb\n",
    "#This can only be done with leaf nodes that have\n",
    "#required_graph property set to true\n",
    "\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "996441ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#If we just want to do forward computations\n",
    "#we can disable gradient tracking\n",
    "\n",
    "z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5e4364a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#Same thing but with a different function\n",
    "\n",
    "z = torch.matmul(x, w)+b\n",
    "z_det = z.detach()\n",
    "print(z_det.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64817112",
   "metadata": {},
   "source": [
    "## Optimizing the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04bbc6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#already wrote this \n",
    "\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37ef75e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning rate finds the best weights\n",
    "##closer to zero means longer, more accurate weights\n",
    "##higher steps means faster and less accurate\n",
    "\n",
    "#Batch size is the number of data samples seen in each epoch\n",
    "\n",
    "#Epochs are the number of times the entire dataset is \n",
    "#passed through the network\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f2c3983",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inits the loss function\n",
    "    #measures tghe degree of dissimilarity of an obtained result\n",
    "    #to the target value\n",
    "    #We want to minimize this \n",
    "    \n",
    "#to calculate loss we make a prediction using the inputs of our\n",
    "#given data sample and compare it against the true data label value\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "381f6e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjusts model parameters to reduce model error in each training step\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#INSIDE:\n",
    "    #Calls optimizer.zero_grad() to reset the gradients of the model parameters\n",
    "            #This is to prevent double counting\n",
    "    #Back-propagates the prediction loss with loss.backwards() \n",
    "    \n",
    "    #Cals optimizer.step() to adjust the parameters by the gradients collected in the backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cf290be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Full implementation:\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        #computer prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        #Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100 *correct):0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b13f137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " ----------------------------\n",
      "loss: 2.306163 [    0/60000]\n",
      "loss: 2.300706 [ 6400/60000]\n",
      "loss: 2.291264 [12800/60000]\n",
      "loss: 2.281506 [19200/60000]\n",
      "loss: 2.264656 [25600/60000]\n",
      "loss: 2.262156 [32000/60000]\n",
      "loss: 2.273452 [38400/60000]\n",
      "loss: 2.259865 [44800/60000]\n",
      "loss: 2.261069 [51200/60000]\n",
      "loss: 2.229286 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 42.0%, Avg loss: 0.035021 \n",
      "\n",
      "Epoch 2\n",
      " ----------------------------\n",
      "loss: 2.263215 [    0/60000]\n",
      "loss: 2.235175 [ 6400/60000]\n",
      "loss: 2.212063 [12800/60000]\n",
      "loss: 2.209132 [19200/60000]\n",
      "loss: 2.152148 [25600/60000]\n",
      "loss: 2.162263 [32000/60000]\n",
      "loss: 2.192261 [38400/60000]\n",
      "loss: 2.158315 [44800/60000]\n",
      "loss: 2.162209 [51200/60000]\n",
      "loss: 2.117159 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 45.8%, Avg loss: 0.032996 \n",
      "\n",
      "Epoch 3\n",
      " ----------------------------\n",
      "loss: 2.152061 [    0/60000]\n",
      "loss: 2.092113 [ 6400/60000]\n",
      "loss: 2.035079 [12800/60000]\n",
      "loss: 2.065351 [19200/60000]\n",
      "loss: 1.959420 [25600/60000]\n",
      "loss: 1.990680 [32000/60000]\n",
      "loss: 2.052766 [38400/60000]\n",
      "loss: 1.983060 [44800/60000]\n",
      "loss: 2.005583 [51200/60000]\n",
      "loss: 1.956547 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 46.3%, Avg loss: 0.029966 \n",
      "\n",
      "Epoch 4\n",
      " ----------------------------\n",
      "loss: 1.988147 [    0/60000]\n",
      "loss: 1.887042 [ 6400/60000]\n",
      "loss: 1.792024 [12800/60000]\n",
      "loss: 1.867509 [19200/60000]\n",
      "loss: 1.728413 [25600/60000]\n",
      "loss: 1.800527 [32000/60000]\n",
      "loss: 1.897389 [38400/60000]\n",
      "loss: 1.808383 [44800/60000]\n",
      "loss: 1.852922 [51200/60000]\n",
      "loss: 1.812375 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 48.9%, Avg loss: 0.027185 \n",
      "\n",
      "Epoch 5\n",
      " ----------------------------\n",
      "loss: 1.836656 [    0/60000]\n",
      "loss: 1.708955 [ 6400/60000]\n",
      "loss: 1.592379 [12800/60000]\n",
      "loss: 1.708464 [19200/60000]\n",
      "loss: 1.563354 [25600/60000]\n",
      "loss: 1.665529 [32000/60000]\n",
      "loss: 1.783900 [38400/60000]\n",
      "loss: 1.692883 [44800/60000]\n",
      "loss: 1.742663 [51200/60000]\n",
      "loss: 1.712851 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 51.4%, Avg loss: 0.025294 \n",
      "\n",
      "Epoch 6\n",
      " ----------------------------\n",
      "loss: 1.722182 [    0/60000]\n",
      "loss: 1.589898 [ 6400/60000]\n",
      "loss: 1.456338 [12800/60000]\n",
      "loss: 1.602777 [19200/60000]\n",
      "loss: 1.454722 [25600/60000]\n",
      "loss: 1.569436 [32000/60000]\n",
      "loss: 1.697743 [38400/60000]\n",
      "loss: 1.611472 [44800/60000]\n",
      "loss: 1.659031 [51200/60000]\n",
      "loss: 1.636120 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 0.023935 \n",
      "\n",
      "Epoch 7\n",
      " ----------------------------\n",
      "loss: 1.632810 [    0/60000]\n",
      "loss: 1.507318 [ 6400/60000]\n",
      "loss: 1.356504 [12800/60000]\n",
      "loss: 1.523095 [19200/60000]\n",
      "loss: 1.376828 [25600/60000]\n",
      "loss: 1.495433 [32000/60000]\n",
      "loss: 1.632366 [38400/60000]\n",
      "loss: 1.552413 [44800/60000]\n",
      "loss: 1.594671 [51200/60000]\n",
      "loss: 1.575050 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 0.022903 \n",
      "\n",
      "Epoch 8\n",
      " ----------------------------\n",
      "loss: 1.562314 [    0/60000]\n",
      "loss: 1.446040 [ 6400/60000]\n",
      "loss: 1.279356 [12800/60000]\n",
      "loss: 1.458956 [19200/60000]\n",
      "loss: 1.319632 [25600/60000]\n",
      "loss: 1.437533 [32000/60000]\n",
      "loss: 1.583014 [38400/60000]\n",
      "loss: 1.510189 [44800/60000]\n",
      "loss: 1.545956 [51200/60000]\n",
      "loss: 1.525580 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 54.7%, Avg loss: 0.022109 \n",
      "\n",
      "Epoch 9\n",
      " ----------------------------\n",
      "loss: 1.506084 [    0/60000]\n",
      "loss: 1.397967 [ 6400/60000]\n",
      "loss: 1.218571 [12800/60000]\n",
      "loss: 1.406395 [19200/60000]\n",
      "loss: 1.277337 [25600/60000]\n",
      "loss: 1.390975 [32000/60000]\n",
      "loss: 1.545798 [38400/60000]\n",
      "loss: 1.481127 [44800/60000]\n",
      "loss: 1.508571 [51200/60000]\n",
      "loss: 1.485266 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.021496 \n",
      "\n",
      "Epoch 10\n",
      " ----------------------------\n",
      "loss: 1.461626 [    0/60000]\n",
      "loss: 1.359999 [ 6400/60000]\n",
      "loss: 1.171150 [12800/60000]\n",
      "loss: 1.364366 [19200/60000]\n",
      "loss: 1.246475 [25600/60000]\n",
      "loss: 1.353905 [32000/60000]\n",
      "loss: 1.517459 [38400/60000]\n",
      "loss: 1.460489 [44800/60000]\n",
      "loss: 1.479114 [51200/60000]\n",
      "loss: 1.452261 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 0.021021 \n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n ----------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42c4dc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "#saving a model\n",
    "\n",
    "torch.save(model.state_dict(), \"data/model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f2254e",
   "metadata": {},
   "source": [
    "## Loading a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af9e5eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import onnxruntime\n",
    "from torch import nn\n",
    "import torch.onnx as onnx\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bcc30617",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "66cd012c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loads the model\n",
    "\n",
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load('data/model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f02b1908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORTING MODEL TO ONNX\n",
    "    #Helps to trian and accelerate inference on any hardware, cloud, or edge device\n",
    "    #Supports java, JS, C#, and ML.NET\n",
    "    \n",
    "input_image = torch.zeros((1, 28, 28))\n",
    "onnx_model = 'data/model.onnx'\n",
    "onnx.export(model, input_image, onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ce98b247",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "x, y = test_data[0][0], test_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ab4125f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precited: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "#create an inference session \n",
    "\n",
    "session = onnxruntime.InferenceSession(onnx_model, None)\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "result = session.run([output_name], {input_name: x.numpy()})\n",
    "predicted, actual = classes[result[0][0].argmax(0)], classes[y]\n",
    "print(f'Precited: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
